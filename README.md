# Lianjia-scrapy
利用 **scrapy** 框架爬取链家网北京地区二手房信息
数据库采用 **MongoDB** 进行存储
需要在 **settings** 中添加数据库连接
之后执行 `scrapy crawl spider` 开启爬虫, 进行数据抓取
